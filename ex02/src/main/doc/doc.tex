\documentclass[a4paper,headings=small]{scrartcl}
\KOMAoptions{DIV=12}

\usepackage[utf8x]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{listings}

% define style of numbering
\numberwithin{equation}{section} % use separate numbering per section
\numberwithin{figure}{section}   % use separate numbering per section

% instead of using indents to denote a new paragraph, we add space before it
\setlength{\parindent}{0pt}
\setlength{\parskip}{10pt plus 1pt minus 1pt}

\title{Automatic Image Analysis - WS12/13 \\ Excercise 2 \\ \emph{Search, Seek and Categorize Images with OpenCV}}
\author{Team e: Marcus Grum, Robin Vobruba, Robert Koppisch, Nicolas Brieger}
\date{\today}

\pdfinfo{%
  /Title    (Automatic Image Analysis - WS12/13 - Excercise 2 - Search, Seek and Categorize Images with OpenCV)
  /Author   (Team e: Marcus Grum, Robin Vobruba, Robert Koppisch, Nicolas Brieger)
  /Creator  ()
  /Producer ()
  /Subject  ()
  /Keywords ()
}

% Simple picture reference
%   Usage: \image{#1}{#2}{#3}
%     #1: file-name of the image
%     #2: percentual width (decimal)
%     #3: caption/description
%
%   Example:
%     \image{myPicture}{0.8}{My huge house}
%     See fig. \ref{fig:myPicture}.
\newcommand{\image}[3]{
	\begin{figure}[htbp]
		\centering
		\includegraphics[width=#2\textwidth]{#1}
		\caption{#3}
		\label{fig:#1}
	\end{figure}
}


\begin{document}


\maketitle



\section{Object Recognition with OpenCV}


\subsection{Documentation}

The following homework deals with object recognition tasks using shape information.
For this, the Fourier Descriptors are used as it is described in the following:

An outline as mathematical function f will be established from the shape of the objects.
It will be used for the object detection based on a functional comparison of two kinds of images:
The \emph{original} image containing the set of unclassified objects 
and the \emph{training} images that contain the objects to be classified separately.

The original picture that shall be analysed could be seen in fig. \ref{fig:../../../target/pic_input}.

\image{../../../target/pic_input}{0.5}{%
		Original picture (\emph{with unclassified objects}).}

The pictures of the database can be seen in fig. \ref{fig:../../../target/pic_db1}.
and fig. \ref{fig:../../../target/pic_db2}. Two types of leaves are to be
recognized and classified. The \emph{training} images are stored in an image database. 
This database can be seen as knowledge representation of the computer. 
In our implementation, they have been loaded in a greyscale.

\image{../../../target/pic_db1}{0.2}{%
		Training picture 1 (\emph{has to be classified}).}
\image{../../../target/pic_db2}{0.5}{%
		Training picture 2 (\emph{has to be classified}).}

As a kind of preparation step, the training images have to be segmented such that the 
function can extract the form of the objects properly.
For this purpose, we use the function threshold(...) and a threshold of 90 to binarize the images.
Then, the function erode(...) deletes small object connections as e.g. between the leaves.
For this, a threshold of 0.01 will be used.
Now, the contours can be extracted.

Representing the raw Contour, the images looks like in fig. \ref{fig:../../../target/pic_RawFourierDescriptor1} 
and in in fig. \ref{fig:../../../target/pic_RawFourierDescriptor2}.

\image{../../../target/pic_RawFourierDescriptor1}{0.2}{%
		Raw picture 1 (\emph{contour has been found}).}
\image{../../../target/pic_RawFourierDescriptor2}{0.5}{%
		Raw picture 2 (\emph{contour has been found}).}
\newpage
The function f stands for the contours of the object, which are represented with help of vectors.
Those are extracted from both, the original image and of the training images.
In order to reach an efficient, precise and robust representation of the function f, 
it will be represented and simplified with help of Fourier Descriptors as it is described in the following:

- Force translation invariance: The first element of the contour vectors is set to 0.\newline
- Force scale invariance:  All elements of the contour vectors are divided by the 2nd element. \newline
- Force rotation invariance: The phase information is deleted. \newline
- Force smaller sensitivity to details: Therefor, the number of frequencies has been reduced.
In our implementation, we have kept the 32 low frequency components, while the rest was set to 0.

Grace of the Fourier Descriptors and the mentioned modifications, 
the recognition algorithm is invariant to object translations,
rotations and scales.

Representing a Contour using the DFT, the image looks like in fig. \ref{fig:../../../target/pic_FourierDescriptor1} 
and in in fig. \ref{fig:../../../target/pic_FourierDescriptor2}.

\image{../../../target/pic_FourierDescriptor1}{0.3}{%
		Reconstructed picture 1 (\emph{comes from Fourier Descriptor Space}).}
\image{../../../target/pic_FourierDescriptor2}{0.5}{%
		Reconstructed picture 2 (\emph{comes from Fourier Descriptor Space}).}

The final picture can be seen in fig. \ref{fig:../../../target/pic_final}.
The first type of leave has been colored in red 
and the second one has been colored in green.

\image{../../../target/pic_final}{0.5}{%
		Original picture (\emph{with classified objects}).} 

Here can be seen, that the implementation of our algorithm works quite well.
The two types of leaves have been classified correctly.

\section{Optional}

\subsection{What kind of problems do you encounter?}

Firstly, overlaps do disturb the shape recognition, e.g. when two leaves are overlapping,
it will be hard for the algorithm to apply the contour shapes.

Secondly, there do exist 3d objects that have no similar 2d projections. Those will be hard to distinguish,
e.g. the 2d projection of a ball is very similar to the 2d projection of a bottle from downside.

Thirdly, objects, that distinguish only in their texture can not be recognized at all, 
because the algorithm only covers the object's shape.

\subsection{How could those problems be solved?}

For the overlap problem, one could install a gadget, that ensures that objects are separated properly.
This could a ventilator be, that separates the objects with its wind. 
Additionally, one could prepare our algorithm in a way, that it uses certain overlaps of the same
contour as well or one could use just certain subparts of the contour for recognition.
The 3d problem could be solved in using a second camera that operates together with the first one.
The texture problem could be solved in using a texture recognition algorithm that cooperates with
our approach, independent from the question how it looks like.

\subsection{What kind of classification tasks should not be addressed with
this approach?}

Searching tasks can not be solved by the use of this approach because of possible overlaps
of the searching objects.
Control tasks like they will be used in newspaper productions to kick broken newspapers from
the assembly line can watch for damages in the newspaper because the observation is only in 2d,
but any further control tasks in 3d space will be much more difficult.
Material recognition tasks should not use this approach 
because a as a robot, that has to prepare different clothing materials, can not distinguish them.

\end{document}
